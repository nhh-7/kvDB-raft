## 本项目如何保证线性一致性？

1. 利用 Raft 的强一致性保证
2. `ClientId` + `RequestId` 幂等控制（避免重复执行）；每个客户端请求中包含唯一的 `clientId`和`requestId`，如果该 `(ClientId, RequestId)` 已处理过，**不重复提交给状态机执行**，直接返回上一次执行结果
3. 每个请求阻塞等待 Raft commit & apply 完成
4. Get 请求也走 Raft 日志， 避免出现 “读取的是未生效写入前的旧数据”，从而保证强一致读
5. 只有 Leader 才能处理客户端请求， 避免了多 Leader 写乱序、旧 Leader 服务不一致的问题
6. 线性一致的重试机制（Clerk 端）， 如果`RPC` 返回 `ErrWrongLeader` 或超时，会重试其它节点，最终一定会找到当前 Leader，使请求被线性执行

## Raft算法的基本原理

包括领导者选举、日志复制和安全性保障。

Raft算法是一种分布式算法，旨在解决分布式系统中的一致性问题，相对于Paxos算法而言更易于理解和实
现。
Raft算法将系统中的所有节点分为三类角色:领导者(leader)、跟随者(follower)和候选人(candidate)。其选举机制确保系统中的一个节点被选为领导者(leader)，领导者负责处理客户端的请求，并将该请求封装成日志复制到其他节点。
Raft算法的基本原理包括以下几个关键步骤:

1. 领导者选举(Leader Election):Follower节点会在一个随机的超时时间内等待收到来自Leader节点的心跳消息。如果在超时时间内没有收到心跳消息，该节点就会成为候选人并发起选举。候选人向其他节点发送投票请求，并在得到大多数节点的投票后成为新的领导者。
2. 日志复制(Log Replication):一旦领导者选举完成，新的领导者就会接收客户端的请求，并将更新的日志条目复制到其他节点。当大多数节点都成功复制了这些日志条目时，这些日志被认为是提交的，可以应用到节点的状态机中。
3. 安全性(Safety):Raft算法通过确保在选举中只有一个领导者(单一领导者)、大多数节点的一致性以及只有领导者可以处理客户端请求等方式保证分布式系统的安全性

## 在什么情况下会触发领导者选举?


在Raft算法中，领导者选举会在以下情况下触发:

1. 当系统启动时，所有节点都处于初始状态，没有领导者，
2. 当领导者节点因网络分区、宕机或其他原因失效时，导致系统中没有活跃的领导者。
3. 当节点故障恢复或者被网络分区时，它可能会检测到当前没有领导者，因此会成为候选人并发起选举

## Raft是如何通过日志复制来保证数据一致性的?

主要是两个机制(特点):

1. Leader Append Entries:领导者追加日志条目，即只有leader可以接受外部请求并将请求打包成日志向follower同步自己的日志，这样保证提交过的日志不会被覆盖掉。
2. commit机制，领导者发现大多数节点都已经成功复制了某个日志条目后，该日志条目被视为已经提交从而保证了数据的一致性。

## Raft是如何保证安全性的?讨论一致性、可用性和分区容错性之间的权衡。

在权衡一致性、可用性和分区容错性时，Raft算法倾向于优先保证一致性和分区容错性。它通过保证大多
数节点的确认和限制领导者选举条件来确保一致性，通过选举机制和日志复制来保证分区容错性。同时，
Raft也兼顾了系统的可用性，确保在领导者失效后能够快速进行新的领导者选举，并继续提供服务。

## 什么是选举超时?它的作用是什么?

follower和candidate都会有选举超时的机制。

- 在follower时:选举超时的意义是发起选举，变成candidate;
- 在candidate时:candidate会选举超时，如果选举成功就会变成leader;如果选举失败就会变成candidate(选举超时)或者follower(发现合适的leader)。

## 选举超时的时间是如何设置的?

设置为一个一定范围内的随机值，其要根据心跳时间，`rpc`延迟，数据操作延迟综合考虑。
范围：一般来说选举超时时间要大于一次完整心跳的日志同步处理时间。
为何随机：选举超时的日的是防止无止境的等待导致所有人都成不了leader，如果超时时间又一样，那么
大家又一起选举，又会不断循环，那么一个随机值可以让某些节点早点重新发起选举，防止大家一起选举
导致死循环。

## Raft中的日志条目是怎么提交的？

1. Leader接收客户端请求:当客户端向Raft系统提交请求时，请求会首先发送到Raft集群中的Leader节点，
2. Leader将请求转换为日志条目:Leader将接收到的客户端请求转换为一条日志条目，并附加到其本地日志中，
3. Leader广播日志条目:Leader向其它节点发送包含新日志条目的心跳`RPC`请求(`AppendEntries` `RPC`)
4. `Folower`节点接收并附加日志条目:Follower节点接收到Leader的附加日志请求后，将新的日志条目附加到其本地日志中。
5. Follower节点响应`Leader： Follower`节点在成功附加日志后，向Leader发送成功的响应。
6. Leader确认提交:当Leader收到大多数节点的附加成功响应时，将日志条目视为已提交。
7. Leader提交到状态机:Leader将已提交的日志条目应用到其状态机中，以执行相应的操作。
8. **Leader通知Followers提交**:Leader会通知其它节点已提交的日志索引，以便它们也可以将相应的日志条目提交到其状态机中。
9. Follower提交到状态机:Follower节点收到Leader的提交通知后，将对应的已提交日志条目应用到其状态机中。

## 什么条件下才能提交日志条目？

1. 该日志条目被当前 Leader 所在的任期（term）创建
2. 该日志条目被多数节点复制

## Raft算法在实际场景中的应用

1. 一些常见的配置中心，比如`zookeeper`
2. 分布式数据库比如 `TIKV`

## 与`Paxos`算法相比，Raft有哪些优势和不同之处?

Raft相对于`Paxos`算法来说，更易理解、实现和维护，具有更直观的Leader机制和选举过程····

1. Leader机制:Raft入了Leader节点，而`Paxos`中没有Leader节点的概念。Leader节点负责协调和
   领导整个一致性过程，而Follower节点只需按照Leader的指示执行操作。
2. 日志复制:在Raft中，所有的日志条目都通过Leader节点进行复制和提交，而`Paxos`中的日志复制是通过多个角色相互协作完成的。
3. 角色切换:Raft中Leader节点失效后，集群可以快速选举新的Leader节点，而`Paxos`中角色的切换较为复杂，需要进行更多的投票和协调，
4. 更强的可读性:Raft算法更加直观和易于理解，它的设计目标之一就是提供更好的可读性和可理解性。相比之下，`Paxos`算法相对更加抽象和复杂。

## Raft算法在分布式系统中有哪些常见的问题和挑战?

1. Leader瓶颈:Raft算法中的Leader节点负责所有的客户端请求的处理和只志复制，这可能会成为系统
   的瓶颈。如果Leader节点负载过重或者发生故障，会导致整个系统的性能下降。
2. 网络分区:Raft算法需要保证在网络分区情况下的一致性，这可能会导致在网络分区恢复后需要进行数据的合并和冲突解决，增加了一致性维护的复杂性。
3. 节点故障处理:当节点发生故障时，Raft需要进行Leader的重新选举，这可能导致一段时间内系统的不可用性和性能下降，尤其是在节点频繁发生故障时。
4. 日志复制延迟:Raft算法要求日志复制必须在大多数节点上完成后才能提交，这可能导致日志复制的延迟，影响系统的实时性能。
5. 节点动态变更:Raft算法在节点动态加入或退出时需要进行配置变更，这可能会导致系统的不稳定和数据的不一致，需要谨慎处理。
6. 一致性保证:虽然Raft算法保证了强一致性，但在一些特殊情况下(如网络分区、节点故障等)，可能会导致一致性级别的降低或者一致性协议的不满足，需要额外的机制来解决。

## 如何处理网络分区的情况?

 这个要结合多种情况分析，比如leader宕机、非leader宕机;少数节点分区、多数节点分区。然后这几种情况还可以相互组合

1. Leader宕机
   - 如果 Leader 发生宕机，网络中的其余节点会检测到心跳超时，触发新的选举:
   - 如果多数派分区存在，则新的 Leader 会在多数派中被选举产生
   - 选举完成后，新 Leader 会将自己的日志与集群中的其余节点同步，最终恢复一致性。
   - 如果没有多数派，则无法选举出新Leader，系统会停止提供服务，直到分区恢
     复。
2. 非Leader 宕机
   - 非 Leader 宕机不会影响服务，只是减少了参与日志复制的节点数量。
   - 当该节点重新加入集群时，会从当前 Leader 同步最新的日志数据，恢复一致性。
3. 少数节点分区
   - 少数节点分区不会影响服务:
   - Leader 会维持对多数节点的控制，继续正常工作。
   - 被分区的少数节点无法参与选举，也无法向 Leader发送心跳响应。
   - 当分区恢复后，少数派节点会与 Leader 同步，更新到最新的状态。
4. 多数节点分区
   - 如果 Leader 处于少数派分区，多数派会触发选举产生新的 Leader。
   - 被分区的少数派中的 Leader 会发现无法与多数派通信，并因为任期超时降级为 Follower。
   - 当网络分区恢复时，旧 Leader 会向新 Leader 请求日志同步，最终达成一致性。
